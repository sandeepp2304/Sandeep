{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_Names=[\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\HP\\\\Desktop\\\\DATA SCIENCE\\\\MACHINE LEARNING NOTES\\\\car.data.txt\",sep = \",\",names=col_Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  buying  maint doors persons lug_boot safety  class\n",
      "0  vhigh  vhigh     2       2    small    low  unacc\n",
      "1  vhigh  vhigh     2       2    small    med  unacc\n",
      "2  vhigh  vhigh     2       2    small   high  unacc\n",
      "3  vhigh  vhigh     2       2      med    low  unacc\n",
      "4  vhigh  vhigh     2       2      med    med  unacc\n",
      "       buying  maint  doors persons lug_boot safety  class\n",
      "count    1728   1728   1728    1728     1728   1728   1728\n",
      "unique      4      4      4       3        3      3      4\n",
      "top     vhigh  vhigh  5more       2      big    med  unacc\n",
      "freq      432    432    432     576      576    576   1210\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying      1728 non-null object\n",
      "maint       1728 non-null object\n",
      "doors       1728 non-null object\n",
      "persons     1728 non-null object\n",
      "lug_boot    1728 non-null object\n",
      "safety      1728 non-null object\n",
      "class       1728 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n",
      "None\n",
      "Index(['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.head())  # head method show only first 5 rows\n",
    "print(data.describe())\n",
    "print(data.info())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      0\n",
       "maint       0\n",
       "doors       0\n",
       "persons     0\n",
       "lug_boot    0\n",
       "safety      0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.iloc[:,0:6]\n",
    "y=data.iloc[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "      <th>doors_3</th>\n",
       "      <th>doors_4</th>\n",
       "      <th>doors_5more</th>\n",
       "      <th>persons_4</th>\n",
       "      <th>persons_more</th>\n",
       "      <th>lug_boot_med</th>\n",
       "      <th>lug_boot_small</th>\n",
       "      <th>safety_low</th>\n",
       "      <th>safety_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_low  buying_med  buying_vhigh  maint_low  maint_med  maint_vhigh  \\\n",
       "0           0           0             1          0          0            1   \n",
       "1           0           0             1          0          0            1   \n",
       "2           0           0             1          0          0            1   \n",
       "3           0           0             1          0          0            1   \n",
       "4           0           0             1          0          0            1   \n",
       "\n",
       "   doors_3  doors_4  doors_5more  persons_4  persons_more  lug_boot_med  \\\n",
       "0        0        0            0          0             0             0   \n",
       "1        0        0            0          0             0             0   \n",
       "2        0        0            0          0             0             0   \n",
       "3        0        0            0          0             0             1   \n",
       "4        0        0            0          0             0             1   \n",
       "\n",
       "   lug_boot_small  safety_low  safety_med  \n",
       "0               1           1           0  \n",
       "1               1           0           1  \n",
       "2               1           0           0  \n",
       "3               0           1           0  \n",
       "4               0           0           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= pd.get_dummies(X, drop_first=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12309e7b048>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count plot\n",
    "sns.countplot(y,label=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,confusion_matrix,accuracy_score\n",
    "# split data train 70 % and test 30 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'random_state': 123}\n",
      "****** report on test data********************************\n",
      "0.7552986512524085\n",
      "[[ 77  13  46   9]\n",
      " [ 10   2   3   8]\n",
      " [ 26   3 309   3]\n",
      " [  5   1   0   4]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.65      0.53      0.59       145\n",
      "       good       0.11      0.09      0.10        23\n",
      "      unacc       0.86      0.91      0.88       341\n",
      "      vgood       0.17      0.40      0.24        10\n",
      "\n",
      "avg / total       0.76      0.76      0.75       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.9181141439205955\n",
      "[[266  16  55  15]\n",
      " [  0  34   5   6]\n",
      " [  0   0 792   2]\n",
      " [  0   0   0  18]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      0.76      0.86       352\n",
      "       good       0.68      0.76      0.72        45\n",
      "      unacc       0.93      1.00      0.96       794\n",
      "      vgood       0.44      1.00      0.61        18\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DesicionTree\n",
    "#importing modules\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#making the instance\n",
    "model= DecisionTreeClassifier(random_state=1234)\n",
    "#Hyper Parameters Set\n",
    "params = {'criterion':['gini','entropy'],\n",
    "          'max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11],\n",
    "          'random_state':[123]}\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Learning\n",
    "model1.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "#Prediction\n",
    "y_pred_1=model1.predict(X_test)\n",
    "y_pred_2=model1.predict(X_train)\n",
    "\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.8998073217726397\n",
      "[[ 85   4   8   2]\n",
      " [ 10  13   0   3]\n",
      " [ 16   2 350   0]\n",
      " [  7   0   0  19]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.72      0.86      0.78        99\n",
      "       good       0.68      0.50      0.58        26\n",
      "      unacc       0.98      0.95      0.96       368\n",
      "      vgood       0.79      0.73      0.76        26\n",
      "\n",
      "avg / total       0.90      0.90      0.90       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "1.0\n",
      "[[266   0   0   0]\n",
      " [  0  50   0   0]\n",
      " [  0   0 852   0]\n",
      " [  0   0   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      1.00      1.00       266\n",
      "       good       1.00      1.00      1.00        50\n",
      "      unacc       1.00      1.00      1.00       852\n",
      "      vgood       1.00      1.00      1.00        41\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf=DecisionTreeClassifier(random_state=123)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred_1=clf.predict(X_test)f\n",
    "y_pred_2=clf.predict(X_train)\n",
    "\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'bootstrap': False, 'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1, 'random_state': 126}\n",
      "****** report on test data********************************\n",
      "0.9017341040462428\n",
      "[[ 96   9   8   7]\n",
      " [  6   8   0   3]\n",
      " [ 16   2 350   0]\n",
      " [  0   0   0  14]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.81      0.80      0.81       120\n",
      "       good       0.42      0.47      0.44        17\n",
      "      unacc       0.98      0.95      0.96       368\n",
      "      vgood       0.58      1.00      0.74        14\n",
      "\n",
      "avg / total       0.91      0.90      0.90       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.9983457402812241\n",
      "[[266   0   1   0]\n",
      " [  0  49   0   0]\n",
      " [  0   0 851   0]\n",
      " [  0   1   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      1.00      1.00       267\n",
      "       good       0.98      1.00      0.99        49\n",
      "      unacc       1.00      1.00      1.00       851\n",
      "      vgood       1.00      0.98      0.99        42\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Randomforest\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#making the instance\n",
    "model=RandomForestClassifier()\n",
    "#hyper parameters set\n",
    "params = {'criterion':['gini','entropy'],\n",
    "          'max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'n_estimators':[10,15,20,25,30],\n",
    "          'min_samples_leaf':[1,2,3],\n",
    "          'min_samples_split':[3,4,5,6,7], \n",
    "          'random_state':[123],\n",
    "          'bootstrap': [True,False],\n",
    "          'random_state':[126],\n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "model2 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#learning\n",
    "model2.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model2.best_params_)\n",
    "#Prediction\n",
    "y_pred_1=model2.predict(X_test)\n",
    "y_pred_2=model2.predict(X_train)\n",
    "\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.8651252408477842\n",
      "[[ 96  11  19   9]\n",
      " [  5   6   0   6]\n",
      " [ 16   1 339   1]\n",
      " [  1   1   0   8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.81      0.71      0.76       135\n",
      "       good       0.32      0.35      0.33        17\n",
      "      unacc       0.95      0.95      0.95       357\n",
      "      vgood       0.33      0.80      0.47        10\n",
      "\n",
      "avg / total       0.88      0.87      0.87       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.9966914805624483\n",
      "[[264   0   2   0]\n",
      " [  0  50   0   0]\n",
      " [  1   0 850   0]\n",
      " [  1   0   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.99      0.99      0.99       266\n",
      "       good       1.00      1.00      1.00        50\n",
      "      unacc       1.00      1.00      1.00       851\n",
      "      vgood       1.00      0.98      0.99        42\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf4=RandomForestClassifier(random_state=124)\n",
    "clf4.fit(X_train,y_train)\n",
    "y_pred_1=clf4.predict(X_test)\n",
    "y_pred_2=clf4.predict(X_train)\n",
    "\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'C': 11, 'gamma': 0.1, 'kernel': 'rbf', 'random_state': 143}\n",
      "****** report on test data********************************\n",
      "0.9672447013487476\n",
      "[[108   0   4   2]\n",
      " [  7  19   0   1]\n",
      " [  1   0 354   0]\n",
      " [  2   0   0  21]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.92      0.95      0.93       114\n",
      "       good       1.00      0.70      0.83        27\n",
      "      unacc       0.99      1.00      0.99       355\n",
      "      vgood       0.88      0.91      0.89        23\n",
      "\n",
      "avg / total       0.97      0.97      0.97       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.9942100909842845\n",
      "[[264   0   2   0]\n",
      " [  2  50   3   0]\n",
      " [  0   0 847   0]\n",
      " [  0   0   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.99      0.99      0.99       266\n",
      "       good       1.00      0.91      0.95        55\n",
      "      unacc       0.99      1.00      1.00       847\n",
      "      vgood       1.00      1.00      1.00        41\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#making the instance\n",
    "model=SVC()\n",
    "#Hyper Parameters Set\n",
    "params = {'C': [6,7,8,9,10,11,12], \n",
    "          'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "          'kernel': ['linear','rbf'],\n",
    "         'random_state':[143]}\n",
    "#Making models with hyper parameters sets\n",
    "model3 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Learning\n",
    "model3.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model3.best_params_)\n",
    "#Prediction\n",
    "y_pred_1=model3.predict(X_test)\n",
    "y_pred_2=model3.predict(X_train)\n",
    "\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.8805394990366089\n",
      "[[114  19  16  22]\n",
      " [  0   0   0   0]\n",
      " [  4   0 342   1]\n",
      " [  0   0   0   1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.97      0.67      0.79       171\n",
      "       good       0.00      0.00      0.00         0\n",
      "      unacc       0.96      0.99      0.97       347\n",
      "      vgood       0.04      1.00      0.08         1\n",
      "\n",
      "avg / total       0.96      0.88      0.91       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.8883374689826302\n",
      "[[259  50  38  38]\n",
      " [  0   0   0   0]\n",
      " [  7   0 814   2]\n",
      " [  0   0   0   1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.97      0.67      0.80       385\n",
      "       good       0.00      0.00      0.00         0\n",
      "      unacc       0.96      0.99      0.97       823\n",
      "      vgood       0.02      1.00      0.05         1\n",
      "\n",
      "avg / total       0.96      0.89      0.92      1209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf1=SVC(random_state=1)\n",
    "clf1.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1=clf1.predict(X_test)\n",
    "y_pred_2=clf1.predict(X_train)\n",
    "\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'C': 10, 'penalty': 'l1', 'random_state': 125}\n",
      "****** report on test data********************************\n",
      "0.8978805394990366\n",
      "[[ 95  10  11   6]\n",
      " [  8   7   1   0]\n",
      " [ 15   0 346   0]\n",
      " [  0   2   0  18]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.81      0.78      0.79       122\n",
      "       good       0.37      0.44      0.40        16\n",
      "      unacc       0.97      0.96      0.96       361\n",
      "      vgood       0.75      0.90      0.82        20\n",
      "\n",
      "avg / total       0.90      0.90      0.90       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.91232423490488\n",
      "[[229  30  26   9]\n",
      " [  8  18   2   0]\n",
      " [ 29   0 824   0]\n",
      " [  0   2   0  32]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.86      0.78      0.82       294\n",
      "       good       0.36      0.64      0.46        28\n",
      "      unacc       0.97      0.97      0.97       853\n",
      "      vgood       0.78      0.94      0.85        34\n",
      "\n",
      "avg / total       0.92      0.91      0.92      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "#Create estimator class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "model = LogisticRegression()\n",
    "\n",
    "#Create param grid\n",
    "params = {'C': [0.001,0.005,0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'penalty': ['l1','l2'],'random_state':[125]}\n",
    "\n",
    "#Making models with hyper parameters sets\n",
    "model4 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Learning\n",
    "model4.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model4.best_params_)\n",
    "#Prediction\n",
    "y_pred_1=model4.predict(X_test)\n",
    "y_pred_2=model4.predict(X_train)\n",
    "\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.8497109826589595\n",
      "[[ 89  18   9  21]\n",
      " [  4   1   1   0]\n",
      " [ 25   0 348   0]\n",
      " [  0   0   0   3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.75      0.65      0.70       137\n",
      "       good       0.05      0.17      0.08         6\n",
      "      unacc       0.97      0.93      0.95       373\n",
      "      vgood       0.12      1.00      0.22         3\n",
      "\n",
      "avg / total       0.90      0.85      0.87       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.8660049627791563\n",
      "[[212  39  32  36]\n",
      " [  5  11   1   0]\n",
      " [ 49   0 819   0]\n",
      " [  0   0   0   5]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.80      0.66      0.72       319\n",
      "       good       0.22      0.65      0.33        17\n",
      "      unacc       0.96      0.94      0.95       868\n",
      "      vgood       0.12      1.00      0.22         5\n",
      "\n",
      "avg / total       0.90      0.87      0.88      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg_reg=LogisticRegression(random_state=12)\n",
    "lg_reg.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1=lg_reg.predict(X_test)\n",
    "y_pred_2=lg_reg.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'random_state': 123}\n",
      "****** report on test data********************************\n",
      "0.9614643545279383\n",
      "[[108   3   2   2]\n",
      " [  7  15   0   2]\n",
      " [  0   0 356   0]\n",
      " [  3   1   0  20]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.92      0.94      0.93       115\n",
      "       good       0.79      0.62      0.70        24\n",
      "      unacc       0.99      1.00      1.00       356\n",
      "      vgood       0.83      0.83      0.83        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "1.0\n",
      "[[266   0   0   0]\n",
      " [  0  50   0   0]\n",
      " [  0   0 852   0]\n",
      " [  0   0   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      1.00      1.00       266\n",
      "       good       1.00      1.00      1.00        50\n",
      "      unacc       1.00      1.00      1.00       852\n",
      "      vgood       1.00      1.00      1.00        41\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingClassifier\n",
    "#importing modules\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#making the instance\n",
    "model=GradientBoostingClassifier()\n",
    "#hyper parameters set\n",
    "params = {'learning_rate': [0.005 ,0.05, 0.5, 1.5],\n",
    "          'max_depth': [2, 4, 6, 8],\n",
    "          'max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'n_estimators':[10,15,20,25,30],\n",
    "          'random_state':[127]\n",
    "          }\n",
    "#Making models with hyper parameters sets\n",
    "model5 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#learning\n",
    "model5.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model1.best_params_)\n",
    "#Prediction\n",
    "y_pred_1 =model5.predict(X_test)\n",
    "y_pred_2 = model5.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.9499036608863198\n",
      "[[104   0   6   3]\n",
      " [  7  18   0   2]\n",
      " [  4   0 352   0]\n",
      " [  3   1   0  19]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.88      0.92      0.90       113\n",
      "       good       0.95      0.67      0.78        27\n",
      "      unacc       0.98      0.99      0.99       356\n",
      "      vgood       0.79      0.83      0.81        23\n",
      "\n",
      "avg / total       0.95      0.95      0.95       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.9851116625310173\n",
      "[[262   0  10   0]\n",
      " [  2  49   3   0]\n",
      " [  2   0 839   0]\n",
      " [  0   1   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.98      0.96      0.97       272\n",
      "       good       0.98      0.91      0.94        54\n",
      "      unacc       0.98      1.00      0.99       841\n",
      "      vgood       1.00      0.98      0.99        42\n",
      "\n",
      "avg / total       0.99      0.99      0.98      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc=GradientBoostingClassifier(random_state=23)\n",
    "gbc.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1 =gbc.predict(X_test)\n",
    "y_pred_2 = gbc.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200, 'random_state': 123}\n",
      "****** report on test data********************************\n",
      "0.8940269749518305\n",
      "[[ 92   8   8   7]\n",
      " [  7   9   0   4]\n",
      " [ 16   2 350   0]\n",
      " [  3   0   0  13]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.78      0.80      0.79       115\n",
      "       good       0.47      0.45      0.46        20\n",
      "      unacc       0.98      0.95      0.96       368\n",
      "      vgood       0.54      0.81      0.65        16\n",
      "\n",
      "avg / total       0.90      0.89      0.90       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "1.0\n",
      "[[266   0   0   0]\n",
      " [  0  50   0   0]\n",
      " [  0   0 852   0]\n",
      " [  0   0   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      1.00      1.00       266\n",
      "       good       1.00      1.00      1.00        50\n",
      "      unacc       1.00      1.00      1.00       852\n",
      "      vgood       1.00      1.00      1.00        41\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model= ExtraTreesClassifier()\n",
    "params= {\"max_depth\": [None],\n",
    "              \"max_features\": [10, 17],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False, True],\n",
    "              \"n_estimators\" :[50,100,200],\n",
    "              \"criterion\": [\"gini\",\"entropy\"],\n",
    "               \"random_state\":[123]\n",
    "\n",
    "          }\n",
    "#Making models with hyper parameters sets\n",
    "model6 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#learning\n",
    "model6.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model6.best_params_)\n",
    "#Prediction\n",
    "y_pred_1 =model6.predict(X_test)\n",
    "y_pred_2 = model6.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.8689788053949904\n",
      "[[ 90  10  15   6]\n",
      " [  9   7   0   6]\n",
      " [ 17   1 343   1]\n",
      " [  2   1   0  11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.76      0.74      0.75       121\n",
      "       good       0.37      0.32      0.34        22\n",
      "      unacc       0.96      0.95      0.95       362\n",
      "      vgood       0.46      0.79      0.58        14\n",
      "\n",
      "avg / total       0.87      0.87      0.87       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "1.0\n",
      "[[266   0   0   0]\n",
      " [  0  50   0   0]\n",
      " [  0   0 852   0]\n",
      " [  0   0   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      1.00      1.00       266\n",
      "       good       1.00      1.00      1.00        50\n",
      "      unacc       1.00      1.00      1.00       852\n",
      "      vgood       1.00      1.00      1.00        41\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model= ExtraTreesClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1 =model.predict(X_test)\n",
    "y_pred_2 = model.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'random_state': 123}\n",
      "****** report on test data********************************\n",
      "0.8959537572254336\n",
      "[[ 87   5   8   5]\n",
      " [  8  14   0   5]\n",
      " [ 16   0 350   0]\n",
      " [  7   0   0  14]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.74      0.83      0.78       105\n",
      "       good       0.74      0.52      0.61        27\n",
      "      unacc       0.98      0.96      0.97       366\n",
      "      vgood       0.58      0.67      0.62        21\n",
      "\n",
      "avg / total       0.90      0.90      0.90       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "1.0\n",
      "[[266   0   0   0]\n",
      " [  0  50   0   0]\n",
      " [  0   0 852   0]\n",
      " [  0   0   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      1.00      1.00       266\n",
      "       good       1.00      1.00      1.00        50\n",
      "      unacc       1.00      1.00      1.00       852\n",
      "      vgood       1.00      1.00      1.00        41\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "model= BaggingClassifier()\n",
    "params= {\n",
    "              \"bootstrap\": [False, True],\n",
    "              \"n_estimators\" :[50,100,200],\n",
    "                \"random_state\":[128]\n",
    "          }\n",
    "#Making models with hyper parameters sets\n",
    "model7 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#learning\n",
    "model7.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model1.best_params_)\n",
    "#Prediction\n",
    "y_pred_1=model7.predict(X_test)\n",
    "y_pred_2 = model7.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.9017341040462428\n",
      "[[ 90   5   9   3]\n",
      " [  8  13   0   5]\n",
      " [ 15   0 349   0]\n",
      " [  5   1   0  16]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.76      0.84      0.80       107\n",
      "       good       0.68      0.50      0.58        26\n",
      "      unacc       0.97      0.96      0.97       364\n",
      "      vgood       0.67      0.73      0.70        22\n",
      "\n",
      "avg / total       0.90      0.90      0.90       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.9958643507030603\n",
      "[[266   0   3   0]\n",
      " [  0  49   0   1]\n",
      " [  0   0 849   0]\n",
      " [  0   1   0  40]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      0.99      0.99       269\n",
      "       good       0.98      0.98      0.98        50\n",
      "      unacc       1.00      1.00      1.00       849\n",
      "      vgood       0.98      0.98      0.98        41\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bac= BaggingClassifier(random_state=13)\n",
    "bac.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1 =bac.predict(X_test)\n",
    "y_pred_2 = bac.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************pip3 install xgboost ,then only run it****************************888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoostclassifier\n",
    "#pip3 install xgboost\n",
    "from xgboost import XGBoostClassifier\n",
    "model= XGBClassifier()\n",
    "params= {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "    'random_state':[129]\n",
    "        }\n",
    "#Making models with hyper parameters sets\n",
    "model8 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#learning\n",
    "model8.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model1.best_params_)\n",
    "#Prediction\n",
    "y_pred_1=model8.predict(X_test)\n",
    "y_pred_2 = model8.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBoostClassifier\n",
    "model= XGBClassifier(random_state=13)\n",
    "model.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1=model.predict(X_test)\n",
    "y_pred_2 = model.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***********************88  END OF XGBoost***************************8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000012301E9EC90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\H...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000012301E9EC90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\H...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(572, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(572, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (572, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=572, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 13, 17, 30, 18, 630751, tzinfo=tzutc()), 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'session': 'f219ae3e1b704f4aa301a730a196aa8c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'f219ae3e1b704f4aa301a730a196aa8c']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 13, 17, 30, 18, 630751, tzinfo=tzutc()), 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'session': 'f219ae3e1b704f4aa301a730a196aa8c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'f219ae3e1b704f4aa301a730a196aa8c'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 13, 17, 30, 18, 630751, tzinfo=tzutc()), 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'session': 'f219ae3e1b704f4aa301a730a196aa8c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-13-c7df19ec14ad>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 12309f35630, executio...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001230A106930, file \"<ipython-input-13-c7df19ec14ad>\", line 16>\n        result = <ExecutionResult object at 12309f35630, executio...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001230A106930, file \"<ipython-input-13-c7df19ec14ad>\", line 16>, result=<ExecutionResult object at 12309f35630, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001230A106930, file \"<ipython-input-13-c7df19ec14ad>\", line 16>\n        self.user_global_ns = {'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"# Visualising the Training set results\\nfrom matp...label('Estimated Salary')\\nplt.legend()\\nplt.show()\", '#Import packages\\nimport numpy as np\\nimport panda...rt matplotlib.pyplot as plt\\nimport seaborn as sns', 'col_Names=[\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"class\"]', '# reading the dataset\\ndata = pd.read_csv(\"C:\\\\\\\\Us...G NOTES\\\\\\\\car.data.txt\",sep = \",\",names=col_Names)', 'data.shape', 'print(data.head())  # head method show only firs...escribe())\\nprint(data.info())\\nprint(data.columns)', '#missing values\\ndata.isna().sum()', 'X= data.iloc[:,0:6]\\ny=data.iloc[:,6]', 'X= pd.get_dummies(X, drop_first=True)\\nX.head()', '#count plot\\nsns.countplot(y,label=\"Count\")', 'from sklearn.model_selection import train_test_s..._test_split(X, y, test_size=0.3, random_state=42)', '# Feature Scaling\\nfrom sklearn.preprocessing imp..._transform(X_train)\\nX_test = sc.transform(X_test)', '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...))\\nprint(classification_report(y_pred_2,y_train))'], 'ListedColormap': <class 'matplotlib.colors.ListedColormap'>, 'Out': {5: (1728, 7), 7: buying      0\nmaint       0\ndoors       0\nperson...oot    0\nsafety      0\nclass       0\ndtype: int64, 9:    buying_low  buying_med  buying_vhigh  maint_l...  0  \n4               0           0           1  , 10: <matplotlib.axes._subplots.AxesSubplot object>}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X':       buying_low  buying_med  buying_vhigh  main...        0           0  \n\n[1728 rows x 15 columns], 'X_test': array([[-0.57066443, -0.5846729 , -0.58085229, .... -0.7163389 ,\n        -0.71237722,  1.44367021]]), 'X_train': array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), '_': <matplotlib.axes._subplots.AxesSubplot object>, ...}\n        self.user_ns = {'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"# Visualising the Training set results\\nfrom matp...label('Estimated Salary')\\nplt.legend()\\nplt.show()\", '#Import packages\\nimport numpy as np\\nimport panda...rt matplotlib.pyplot as plt\\nimport seaborn as sns', 'col_Names=[\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"class\"]', '# reading the dataset\\ndata = pd.read_csv(\"C:\\\\\\\\Us...G NOTES\\\\\\\\car.data.txt\",sep = \",\",names=col_Names)', 'data.shape', 'print(data.head())  # head method show only firs...escribe())\\nprint(data.info())\\nprint(data.columns)', '#missing values\\ndata.isna().sum()', 'X= data.iloc[:,0:6]\\ny=data.iloc[:,6]', 'X= pd.get_dummies(X, drop_first=True)\\nX.head()', '#count plot\\nsns.countplot(y,label=\"Count\")', 'from sklearn.model_selection import train_test_s..._test_split(X, y, test_size=0.3, random_state=42)', '# Feature Scaling\\nfrom sklearn.preprocessing imp..._transform(X_train)\\nX_test = sc.transform(X_test)', '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...))\\nprint(classification_report(y_pred_2,y_train))'], 'ListedColormap': <class 'matplotlib.colors.ListedColormap'>, 'Out': {5: (1728, 7), 7: buying      0\nmaint       0\ndoors       0\nperson...oot    0\nsafety      0\nclass       0\ndtype: int64, 9:    buying_low  buying_med  buying_vhigh  maint_l...  0  \n4               0           0           1  , 10: <matplotlib.axes._subplots.AxesSubplot object>}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X':       buying_low  buying_med  buying_vhigh  main...        0           0  \n\n[1728 rows x 15 columns], 'X_test': array([[-0.57066443, -0.5846729 , -0.58085229, .... -0.7163389 ,\n        -0.71237722,  1.44367021]]), 'X_train': array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), '_': <matplotlib.axes._subplots.AxesSubplot object>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\HP\\002.MACHINE LEARNING\\03.CLASSIFICATION\\05.RANDOM FOREST\\<ipython-input-13-c7df19ec14ad> in <module>()\n     11 params = {'priors':[[0.01, 0.99],[0.1, 0.9], [0.2, 0.8], [0.25, 0.75], [0.3, 0.7],[0.35, 0.65], [0.4, 0.6] ]}\n     12 \n     13 #Making models with hyper parameters sets\n     14 model11 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n     15 #Learning\n---> 16 model11.fit(X_train,y_train)\n     17 #The best hyper parameters set\n     18 print(\"Best Hyper Parameters:\\n\",model11.best_params_)\n     19 #Prediction\n     20 y_pred_1 = model11.predict(X_test)\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=None, error_score='raise', estim...ain_score='warn',\n       scoring=None, verbose=0), X=array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]])\n        y = 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Mar 13 23:00:22 2019\nPID: 6028                    Python 3.6.5: C:\\Users\\HP\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GaussianNB(priors=[0.01, 0.99]), array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, {'score': <function _passthrough_scorer>}, array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), 0, {'priors': [0.01, 0.99]}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GaussianNB(priors=[0.01, 0.99]), array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, {'score': <function _passthrough_scorer>}, array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), 0, {'priors': [0.01, 0.99]})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, scorer={'score': <function _passthrough_scorer>}, train=array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), verbose=0, parameters={'priors': [0.01, 0.99]}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GaussianNB.fit of GaussianNB(priors=[0.01, 0.99])>\n        X_train = array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]])\n        y_train = 45      unacc\n523     unacc\n1677    unacc\n1303  ...      acc\nName: class, Length: 805, dtype: object\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in fit(self=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=array(['unacc', 'unacc', 'unacc', 'unacc', 'unac...    'good', 'acc', 'unacc', 'acc'], dtype=object), sample_weight=None)\n    180         self : object\n    181             Returns self.\n    182         \"\"\"\n    183         X, y = check_X_y(X, y)\n    184         return self._partial_fit(X, y, np.unique(y), _refit=True,\n--> 185                                  sample_weight=sample_weight)\n        sample_weight = None\n    186 \n    187     @staticmethod\n    188     def _update_mean_variance(n_past, mu, var, X, sample_weight=None):\n    189         \"\"\"Compute online update of Gaussian mean and variance.\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in _partial_fit(self=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=array(['unacc', 'unacc', 'unacc', 'unacc', 'unac...    'good', 'acc', 'unacc', 'acc'], dtype=object), classes=array(['acc', 'good', 'unacc', 'vgood'], dtype=object), _refit=True, sample_weight=None)\n    362             # Take into account the priors\n    363             if self.priors is not None:\n    364                 priors = np.asarray(self.priors)\n    365                 # Check that the provide prior match the number of classes\n    366                 if len(priors) != n_classes:\n--> 367                     raise ValueError('Number of priors must match number of'\n    368                                      ' classes.')\n    369                 # Check that the sum is 1\n    370                 if priors.sum() != 1.0:\n    371                     raise ValueError('The sum of the priors should be 1.')\n\nValueError: Number of priors must match number of classes.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 185, in fit\n    sample_weight=sample_weight)\n  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 367, in _partial_fit\n    raise ValueError('Number of priors must match number of'\nValueError: Number of priors must match number of classes.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\HP\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Mar 13 23:00:22 2019\nPID: 6028                    Python 3.6.5: C:\\Users\\HP\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GaussianNB(priors=[0.01, 0.99]), array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, {'score': <function _passthrough_scorer>}, array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), 0, {'priors': [0.01, 0.99]}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GaussianNB(priors=[0.01, 0.99]), array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, {'score': <function _passthrough_scorer>}, array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), 0, {'priors': [0.01, 0.99]})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, scorer={'score': <function _passthrough_scorer>}, train=array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), verbose=0, parameters={'priors': [0.01, 0.99]}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GaussianNB.fit of GaussianNB(priors=[0.01, 0.99])>\n        X_train = array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]])\n        y_train = 45      unacc\n523     unacc\n1677    unacc\n1303  ...      acc\nName: class, Length: 805, dtype: object\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in fit(self=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=array(['unacc', 'unacc', 'unacc', 'unacc', 'unac...    'good', 'acc', 'unacc', 'acc'], dtype=object), sample_weight=None)\n    180         self : object\n    181             Returns self.\n    182         \"\"\"\n    183         X, y = check_X_y(X, y)\n    184         return self._partial_fit(X, y, np.unique(y), _refit=True,\n--> 185                                  sample_weight=sample_weight)\n        sample_weight = None\n    186 \n    187     @staticmethod\n    188     def _update_mean_variance(n_past, mu, var, X, sample_weight=None):\n    189         \"\"\"Compute online update of Gaussian mean and variance.\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in _partial_fit(self=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=array(['unacc', 'unacc', 'unacc', 'unacc', 'unac...    'good', 'acc', 'unacc', 'acc'], dtype=object), classes=array(['acc', 'good', 'unacc', 'vgood'], dtype=object), _refit=True, sample_weight=None)\n    362             # Take into account the priors\n    363             if self.priors is not None:\n    364                 priors = np.asarray(self.priors)\n    365                 # Check that the provide prior match the number of classes\n    366                 if len(priors) != n_classes:\n--> 367                     raise ValueError('Number of priors must match number of'\n    368                                      ' classes.')\n    369                 # Check that the sum is 1\n    370                 if priors.sum() != 1.0:\n    371                     raise ValueError('The sum of the priors should be 1.')\n\nValueError: Number of priors must match number of classes.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Mar 13 23:00:22 2019\nPID: 6028                    Python 3.6.5: C:\\Users\\HP\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GaussianNB(priors=[0.01, 0.99]), array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, {'score': <function _passthrough_scorer>}, array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), 0, {'priors': [0.01, 0.99]}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GaussianNB(priors=[0.01, 0.99]), array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, {'score': <function _passthrough_scorer>}, array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), 0, {'priors': [0.01, 0.99]})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, scorer={'score': <function _passthrough_scorer>}, train=array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), verbose=0, parameters={'priors': [0.01, 0.99]}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GaussianNB.fit of GaussianNB(priors=[0.01, 0.99])>\n        X_train = array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]])\n        y_train = 45      unacc\n523     unacc\n1677    unacc\n1303  ...      acc\nName: class, Length: 805, dtype: object\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in fit(self=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=array(['unacc', 'unacc', 'unacc', 'unacc', 'unac...    'good', 'acc', 'unacc', 'acc'], dtype=object), sample_weight=None)\n    180         self : object\n    181             Returns self.\n    182         \"\"\"\n    183         X, y = check_X_y(X, y)\n    184         return self._partial_fit(X, y, np.unique(y), _refit=True,\n--> 185                                  sample_weight=sample_weight)\n        sample_weight = None\n    186 \n    187     @staticmethod\n    188     def _update_mean_variance(n_past, mu, var, X, sample_weight=None):\n    189         \"\"\"Compute online update of Gaussian mean and variance.\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in _partial_fit(self=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=array(['unacc', 'unacc', 'unacc', 'unacc', 'unac...    'good', 'acc', 'unacc', 'acc'], dtype=object), classes=array(['acc', 'good', 'unacc', 'vgood'], dtype=object), _refit=True, sample_weight=None)\n    362             # Take into account the priors\n    363             if self.priors is not None:\n    364                 priors = np.asarray(self.priors)\n    365                 # Check that the provide prior match the number of classes\n    366                 if len(priors) != n_classes:\n--> 367                     raise ValueError('Number of priors must match number of'\n    368                                      ' classes.')\n    369                 # Check that the sum is 1\n    370                 if priors.sum() != 1.0:\n    371                     raise ValueError('The sum of the priors should be 1.')\n\nValueError: Number of priors must match number of classes.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c7df19ec14ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel11\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#Learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel11\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#The best hyper parameters set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best Hyper Parameters:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel11\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000012301E9EC90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\H...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000012301E9EC90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\H...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(572, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(572, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (572, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=572, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 13, 17, 30, 18, 630751, tzinfo=tzutc()), 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'session': 'f219ae3e1b704f4aa301a730a196aa8c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'f219ae3e1b704f4aa301a730a196aa8c']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 13, 17, 30, 18, 630751, tzinfo=tzutc()), 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'session': 'f219ae3e1b704f4aa301a730a196aa8c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'f219ae3e1b704f4aa301a730a196aa8c'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 13, 17, 30, 18, 630751, tzinfo=tzutc()), 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'session': 'f219ae3e1b704f4aa301a730a196aa8c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0fdbcd1aaf60487c8e62f2aff8a6a4db', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...)\\nprint(classification_report(y_pred_2,y_train))\\n', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-13-c7df19ec14ad>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 12309f35630, executio...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001230A106930, file \"<ipython-input-13-c7df19ec14ad>\", line 16>\n        result = <ExecutionResult object at 12309f35630, executio...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001230A106930, file \"<ipython-input-13-c7df19ec14ad>\", line 16>, result=<ExecutionResult object at 12309f35630, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001230A106930, file \"<ipython-input-13-c7df19ec14ad>\", line 16>\n        self.user_global_ns = {'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"# Visualising the Training set results\\nfrom matp...label('Estimated Salary')\\nplt.legend()\\nplt.show()\", '#Import packages\\nimport numpy as np\\nimport panda...rt matplotlib.pyplot as plt\\nimport seaborn as sns', 'col_Names=[\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"class\"]', '# reading the dataset\\ndata = pd.read_csv(\"C:\\\\\\\\Us...G NOTES\\\\\\\\car.data.txt\",sep = \",\",names=col_Names)', 'data.shape', 'print(data.head())  # head method show only firs...escribe())\\nprint(data.info())\\nprint(data.columns)', '#missing values\\ndata.isna().sum()', 'X= data.iloc[:,0:6]\\ny=data.iloc[:,6]', 'X= pd.get_dummies(X, drop_first=True)\\nX.head()', '#count plot\\nsns.countplot(y,label=\"Count\")', 'from sklearn.model_selection import train_test_s..._test_split(X, y, test_size=0.3, random_state=42)', '# Feature Scaling\\nfrom sklearn.preprocessing imp..._transform(X_train)\\nX_test = sc.transform(X_test)', '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...))\\nprint(classification_report(y_pred_2,y_train))'], 'ListedColormap': <class 'matplotlib.colors.ListedColormap'>, 'Out': {5: (1728, 7), 7: buying      0\nmaint       0\ndoors       0\nperson...oot    0\nsafety      0\nclass       0\ndtype: int64, 9:    buying_low  buying_med  buying_vhigh  maint_l...  0  \n4               0           0           1  , 10: <matplotlib.axes._subplots.AxesSubplot object>}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X':       buying_low  buying_med  buying_vhigh  main...        0           0  \n\n[1728 rows x 15 columns], 'X_test': array([[-0.57066443, -0.5846729 , -0.58085229, .... -0.7163389 ,\n        -0.71237722,  1.44367021]]), 'X_train': array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), '_': <matplotlib.axes._subplots.AxesSubplot object>, ...}\n        self.user_ns = {'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"# Visualising the Training set results\\nfrom matp...label('Estimated Salary')\\nplt.legend()\\nplt.show()\", '#Import packages\\nimport numpy as np\\nimport panda...rt matplotlib.pyplot as plt\\nimport seaborn as sns', 'col_Names=[\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"class\"]', '# reading the dataset\\ndata = pd.read_csv(\"C:\\\\\\\\Us...G NOTES\\\\\\\\car.data.txt\",sep = \",\",names=col_Names)', 'data.shape', 'print(data.head())  # head method show only firs...escribe())\\nprint(data.info())\\nprint(data.columns)', '#missing values\\ndata.isna().sum()', 'X= data.iloc[:,0:6]\\ny=data.iloc[:,6]', 'X= pd.get_dummies(X, drop_first=True)\\nX.head()', '#count plot\\nsns.countplot(y,label=\"Count\")', 'from sklearn.model_selection import train_test_s..._test_split(X, y, test_size=0.3, random_state=42)', '# Feature Scaling\\nfrom sklearn.preprocessing imp..._transform(X_train)\\nX_test = sc.transform(X_test)', '#Naive Bayes\\n#importing modules\\nfrom sklearn.mod...))\\nprint(classification_report(y_pred_2,y_train))'], 'ListedColormap': <class 'matplotlib.colors.ListedColormap'>, 'Out': {5: (1728, 7), 7: buying      0\nmaint       0\ndoors       0\nperson...oot    0\nsafety      0\nclass       0\ndtype: int64, 9:    buying_low  buying_med  buying_vhigh  maint_l...  0  \n4               0           0           1  , 10: <matplotlib.axes._subplots.AxesSubplot object>}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'X':       buying_low  buying_med  buying_vhigh  main...        0           0  \n\n[1728 rows x 15 columns], 'X_test': array([[-0.57066443, -0.5846729 , -0.58085229, .... -0.7163389 ,\n        -0.71237722,  1.44367021]]), 'X_train': array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), '_': <matplotlib.axes._subplots.AxesSubplot object>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\HP\\002.MACHINE LEARNING\\03.CLASSIFICATION\\05.RANDOM FOREST\\<ipython-input-13-c7df19ec14ad> in <module>()\n     11 params = {'priors':[[0.01, 0.99],[0.1, 0.9], [0.2, 0.8], [0.25, 0.75], [0.3, 0.7],[0.35, 0.65], [0.4, 0.6] ]}\n     12 \n     13 #Making models with hyper parameters sets\n     14 model11 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n     15 #Learning\n---> 16 model11.fit(X_train,y_train)\n     17 #The best hyper parameters set\n     18 print(\"Best Hyper Parameters:\\n\",model11.best_params_)\n     19 #Prediction\n     20 y_pred_1 = model11.predict(X_test)\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=None, error_score='raise', estim...ain_score='warn',\n       scoring=None, verbose=0), X=array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]])\n        y = 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Mar 13 23:00:22 2019\nPID: 6028                    Python 3.6.5: C:\\Users\\HP\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GaussianNB(priors=[0.01, 0.99]), array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, {'score': <function _passthrough_scorer>}, array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), 0, {'priors': [0.01, 0.99]}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GaussianNB(priors=[0.01, 0.99]), array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), 1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, {'score': <function _passthrough_scorer>}, array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), 0, {'priors': [0.01, 0.99]})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443,  1.71035805, -0.58085229, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=1178    vgood\n585     unacc\n1552      acc\n1169  ...     acc\nName: class, Length: 1209, dtype: object, scorer={'score': <function _passthrough_scorer>}, train=array([ 380,  382,  385,  386,  388,  390,  391,...1202, 1203, 1204, 1205, 1206,\n       1207, 1208]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 441, 451, 460, 462, 473, 520, 569,\n       616]), verbose=0, parameters={'priors': [0.01, 0.99]}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GaussianNB.fit of GaussianNB(priors=[0.01, 0.99])>\n        X_train = array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]])\n        y_train = 45      unacc\n523     unacc\n1677    unacc\n1303  ...      acc\nName: class, Length: 805, dtype: object\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in fit(self=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=array(['unacc', 'unacc', 'unacc', 'unacc', 'unac...    'good', 'acc', 'unacc', 'acc'], dtype=object), sample_weight=None)\n    180         self : object\n    181             Returns self.\n    182         \"\"\"\n    183         X, y = check_X_y(X, y)\n    184         return self._partial_fit(X, y, np.unique(y), _refit=True,\n--> 185                                  sample_weight=sample_weight)\n        sample_weight = None\n    186 \n    187     @staticmethod\n    188     def _update_mean_variance(n_past, mu, var, X, sample_weight=None):\n    189         \"\"\"Compute online update of Gaussian mean and variance.\n\n...........................................................................\nC:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py in _partial_fit(self=GaussianNB(priors=[0.01, 0.99]), X=array([[-0.57066443, -0.5846729 ,  1.72160809, ....  1.39598728,\n        -0.71237722,  1.44367021]]), y=array(['unacc', 'unacc', 'unacc', 'unacc', 'unac...    'good', 'acc', 'unacc', 'acc'], dtype=object), classes=array(['acc', 'good', 'unacc', 'vgood'], dtype=object), _refit=True, sample_weight=None)\n    362             # Take into account the priors\n    363             if self.priors is not None:\n    364                 priors = np.asarray(self.priors)\n    365                 # Check that the provide prior match the number of classes\n    366                 if len(priors) != n_classes:\n--> 367                     raise ValueError('Number of priors must match number of'\n    368                                      ' classes.')\n    369                 # Check that the sum is 1\n    370                 if priors.sum() != 1.0:\n    371                     raise ValueError('The sum of the priors should be 1.')\n\nValueError: Number of priors must match number of classes.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#making the instance\n",
    "model=GaussianNB()\n",
    "#Hyper Parameters Set\n",
    "params = {'priors':[[0.01, 0.99],[0.1, 0.9], [0.2, 0.8], [0.25, 0.75], [0.3, 0.7],[0.35, 0.65], [0.4, 0.6] ]}\n",
    "\n",
    "#Making models with hyper parameters sets\n",
    "model11 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Learning\n",
    "model11.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model11.best_params_)\n",
    "#Prediction\n",
    "y_pred_1 = model11.predict(X_test)\n",
    "y_pred_2 = model11.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.4913294797687861\n",
      "[[ 46   0 107   0]\n",
      " [ 50  16  60   0]\n",
      " [  0   0 169   0]\n",
      " [ 22   3  22  24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.39      0.30      0.34       153\n",
      "       good       0.84      0.13      0.22       126\n",
      "      unacc       0.47      1.00      0.64       169\n",
      "      vgood       1.00      0.34      0.51        71\n",
      "\n",
      "avg / total       0.61      0.49      0.43       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.4880066170388751\n",
      "[[ 98   0 253   0]\n",
      " [120  44 142   0]\n",
      " [  0   0 407   0]\n",
      " [ 48   6  50  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.37      0.28      0.32       351\n",
      "       good       0.88      0.14      0.25       306\n",
      "      unacc       0.48      1.00      0.65       407\n",
      "      vgood       1.00      0.28      0.44       145\n",
      "\n",
      "avg / total       0.61      0.49      0.43      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model=GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1 = model.predict(X_test)\n",
    "y_pred_2 = model.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'alpha': 1e-05}\n",
      "****** report on test data********************************\n",
      "0.7244701348747592\n",
      "[[ 20   9   2   4]\n",
      " [  1   0   0   0]\n",
      " [ 97  10 356  20]\n",
      " [  0   0   0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.17      0.57      0.26        35\n",
      "       good       0.00      0.00      0.00         1\n",
      "      unacc       0.99      0.74      0.85       483\n",
      "      vgood       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.94      0.72      0.81       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.7477253928866832\n",
      "[[ 53  22   9   6]\n",
      " [  0   5   0   0]\n",
      " [213  23 843  32]\n",
      " [  0   0   0   3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.20      0.59      0.30        90\n",
      "       good       0.10      1.00      0.18         5\n",
      "      unacc       0.99      0.76      0.86      1111\n",
      "      vgood       0.07      1.00      0.14         3\n",
      "\n",
      "avg / total       0.92      0.75      0.81      1209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#multinomial NB\n",
    "#importing modules\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#making the instance\n",
    "model=MultinomialNB()\n",
    "#hyper parameters set\n",
    "params = {'alpha':[0.00001, 0.00005, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 250, 500, 1000]}\n",
    "          \n",
    "#Making models with hyper parameters sets\n",
    "model12 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#learning\n",
    "model12.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model12.best_params_)\n",
    "#Prediction\n",
    "y_pred_1 = model12.predict(X_test)\n",
    "y_pred_2 = model12.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.7244701348747592\n",
      "[[ 20   9   2   3]\n",
      " [  0   0   0   0]\n",
      " [ 98  10 356  21]\n",
      " [  0   0   0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.17      0.59      0.26        34\n",
      "       good       0.00      0.00      0.00         0\n",
      "      unacc       0.99      0.73      0.84       485\n",
      "      vgood       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.94      0.72      0.81       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.7427626137303557\n",
      "[[ 51  23   8   5]\n",
      " [  0   3   0   0]\n",
      " [215  24 844  36]\n",
      " [  0   0   0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.19      0.59      0.29        87\n",
      "       good       0.06      1.00      0.11         3\n",
      "      unacc       0.99      0.75      0.86      1119\n",
      "      vgood       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.93      0.74      0.81      1209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model=MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1 = model.predict(X_test)\n",
    "y_pred_2 = model.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 124}\n",
      "****** report on test data********************************\n",
      "0.8882466281310212\n",
      "[[ 80   4   9   2]\n",
      " [  8  13   0   3]\n",
      " [ 23   2 349   0]\n",
      " [  7   0   0  19]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.68      0.84      0.75        95\n",
      "       good       0.68      0.54      0.60        24\n",
      "      unacc       0.97      0.93      0.95       374\n",
      "      vgood       0.79      0.73      0.76        26\n",
      "\n",
      "avg / total       0.90      0.89      0.89       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "1.0\n",
      "[[266   0   0   0]\n",
      " [  0  50   0   0]\n",
      " [  0   0 852   0]\n",
      " [  0   0   0  41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      1.00      1.00       266\n",
      "       good       1.00      1.00      1.00        50\n",
      "      unacc       1.00      1.00      1.00       852\n",
      "      vgood       1.00      1.00      1.00        41\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model =AdaBoostClassifier()\n",
    "#Hyper Parameters Set\n",
    "cl1 = LogisticRegression()\n",
    "cl2 = DecisionTreeClassifier()\n",
    "cl3 = GaussianNB()\n",
    "params = {'base_estimator':[cl1, cl2, cl3],\n",
    "        'random_state':[124]\n",
    "        }\n",
    "#Making models with hyper parameters sets\n",
    "model13 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Learning\n",
    "model13.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model13.best_params_)\n",
    "#Prediction\n",
    "y_pred_1=model13.predict(X_test)\n",
    "y_pred_2 = model13.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.8015414258188824\n",
      "[[ 47   8   8   9]\n",
      " [ 23   8   4   0]\n",
      " [ 43   3 346   0]\n",
      " [  5   0   0  15]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.40      0.65      0.49        72\n",
      "       good       0.42      0.23      0.30        35\n",
      "      unacc       0.97      0.88      0.92       392\n",
      "      vgood       0.62      0.75      0.68        20\n",
      "\n",
      "avg / total       0.84      0.80      0.81       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.8163771712158809\n",
      "[[112  12  24   8]\n",
      " [ 45  31  17   0]\n",
      " [ 92   7 811   0]\n",
      " [ 17   0   0  33]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.42      0.72      0.53       156\n",
      "       good       0.62      0.33      0.43        93\n",
      "      unacc       0.95      0.89      0.92       910\n",
      "      vgood       0.80      0.66      0.73        50\n",
      "\n",
      "avg / total       0.85      0.82      0.82      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "model=AdaBoostClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1 = model.predict(X_test)\n",
    "y_pred_2 = model.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.8940269749518305\n",
      "[[106  13  14  14]\n",
      " [  5   6   1   0]\n",
      " [  7   0 342   0]\n",
      " [  0   0   1  10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.90      0.72      0.80       147\n",
      "       good       0.32      0.50      0.39        12\n",
      "      unacc       0.96      0.98      0.97       349\n",
      "      vgood       0.42      0.91      0.57        11\n",
      "\n",
      "avg / total       0.91      0.89      0.90       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.9032258064516129\n",
      "[[245  30  49  14]\n",
      " [  6  20   1   2]\n",
      " [ 15   0 802   0]\n",
      " [  0   0   0  25]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.92      0.72      0.81       338\n",
      "       good       0.40      0.69      0.51        29\n",
      "      unacc       0.94      0.98      0.96       817\n",
      "      vgood       0.61      1.00      0.76        25\n",
      "\n",
      "avg / total       0.92      0.90      0.90      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model=LinearDiscriminantAnalysis()\n",
    "model.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1 = model.predict(X_test)\n",
    "y_pred_2 = model.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:706: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:709: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.22736030828516376\n",
      "[[118  19 358  24]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      0.23      0.37       519\n",
      "       good       0.00      0.00      0.00         0\n",
      "      unacc       0.00      0.00      0.00         0\n",
      "      vgood       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.23      0.37       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.22001654259718775\n",
      "[[266  50 852  41]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       1.00      0.22      0.36      1209\n",
      "       good       0.00      0.00      0.00         0\n",
      "      unacc       0.00      0.00      0.00         0\n",
      "      vgood       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.22      0.36      1209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "model=QuadraticDiscriminantAnalysis()\n",
    "model.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1 = model.predict(X_test)\n",
    "y_pred_2 = model.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'algorithm': 'auto', 'leaf_size': 1, 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "****** report on test data********************************\n",
      "0.815028901734104\n",
      "[[ 74  15  10   9]\n",
      " [  7   1   1  10]\n",
      " [ 37   3 347   4]\n",
      " [  0   0   0   1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.63      0.69      0.65       108\n",
      "       good       0.05      0.05      0.05        19\n",
      "      unacc       0.97      0.89      0.93       391\n",
      "      vgood       0.04      1.00      0.08         1\n",
      "\n",
      "avg / total       0.86      0.82      0.84       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.8792390405293631\n",
      "[[198  20  15  10]\n",
      " [  5  20   0   6]\n",
      " [ 63   8 837  17]\n",
      " [  0   2   0   8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.74      0.81      0.78       243\n",
      "       good       0.40      0.65      0.49        31\n",
      "      unacc       0.98      0.90      0.94       925\n",
      "      vgood       0.20      0.80      0.31        10\n",
      "\n",
      "avg / total       0.91      0.88      0.89      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#kNearestNeighbors\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#making the instance\n",
    "model = KNeighborsClassifier(n_jobs=-1)\n",
    "#Hyper Parameters Set\n",
    "params = {'n_neighbors':[5,6,7,8,9,10],\n",
    "          'leaf_size':[1,2,3,5,6,7,8,20],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
    "          }\n",
    "#Making models with hyper parameters sets\n",
    "model9 = GridSearchCV(model, param_grid=params, n_jobs=1)\n",
    "#Learning\n",
    "model9.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model9.best_params_)\n",
    "#Prediction\n",
    "#Prediction\n",
    "y_pred_1=model9.predict(X_test)\n",
    "y_pred_2 = model9.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.815028901734104\n",
      "[[ 74  15  10   9]\n",
      " [  7   1   1  10]\n",
      " [ 37   3 347   4]\n",
      " [  0   0   0   1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.63      0.69      0.65       108\n",
      "       good       0.05      0.05      0.05        19\n",
      "      unacc       0.97      0.89      0.93       391\n",
      "      vgood       0.04      1.00      0.08         1\n",
      "\n",
      "avg / total       0.86      0.82      0.84       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.8792390405293631\n",
      "[[198  20  15  10]\n",
      " [  5  20   0   6]\n",
      " [ 63   8 837  17]\n",
      " [  0   2   0   8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.74      0.81      0.78       243\n",
      "       good       0.40      0.65      0.49        31\n",
      "      unacc       0.98      0.90      0.94       925\n",
      "      vgood       0.20      0.80      0.31        10\n",
      "\n",
      "avg / total       0.91      0.88      0.89      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1=model.predict(X_test)\n",
    "y_pred_2 = model.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'alpha': 0.01, 'loss': 'squared_hinge', 'n_iter': 10, 'penalty': 'l1', 'random_state': 124}\n",
      "****** report on test data********************************\n",
      "0.9132947976878613\n",
      "[[ 99  12   8   3]\n",
      " [  7   5   1   0]\n",
      " [ 12   0 349   0]\n",
      " [  0   2   0  21]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.84      0.81      0.82       122\n",
      "       good       0.26      0.38      0.31        13\n",
      "      unacc       0.97      0.97      0.97       361\n",
      "      vgood       0.88      0.91      0.89        23\n",
      "\n",
      "avg / total       0.92      0.91      0.92       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.913151364764268\n",
      "[[227  25  25   7]\n",
      " [ 11  22   6   0]\n",
      " [ 25   0 821   0]\n",
      " [  3   3   0  34]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.85      0.80      0.83       284\n",
      "       good       0.44      0.56      0.49        39\n",
      "      unacc       0.96      0.97      0.97       846\n",
      "      vgood       0.83      0.85      0.84        40\n",
      "\n",
      "avg / total       0.92      0.91      0.91      1209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#SGD classifier\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#making the instance\n",
    "model = SGDClassifier()\n",
    "#Hyper Parameters Set\n",
    "params = {\n",
    "    \"n_iter\": [5, 10, 20, 50, 100, 1000],\n",
    "    \"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\", \"l1\"],\n",
    "    'random_state':[124]\n",
    "        }\n",
    "#Making models with hyper parameters sets\n",
    "model10 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Learning\n",
    "model10.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model10.best_params_)\n",
    "#Prediction\n",
    "y_pred_1=model10.predict(X_test)\n",
    "y_pred_2 = model10.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** report on test data********************************\n",
      "0.8805394990366089\n",
      "[[ 84   7   9   6]\n",
      " [  4  12   1   5]\n",
      " [ 28   0 348   0]\n",
      " [  2   0   0  13]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.71      0.79      0.75       106\n",
      "       good       0.63      0.55      0.59        22\n",
      "      unacc       0.97      0.93      0.95       376\n",
      "      vgood       0.54      0.87      0.67        15\n",
      "\n",
      "avg / total       0.89      0.88      0.88       519\n",
      "\n",
      "****** report on train  data********************************\n",
      "0.8866832092638545\n",
      "[[211  20  35  13]\n",
      " [ 12  30   5   9]\n",
      " [ 40   0 812   0]\n",
      " [  3   0   0  19]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        acc       0.79      0.76      0.77       279\n",
      "       good       0.60      0.54      0.57        56\n",
      "      unacc       0.95      0.95      0.95       852\n",
      "      vgood       0.46      0.86      0.60        22\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "#Prediction\n",
    "y_pred_1=model.predict(X_test)\n",
    "y_pred_2 = model.predict(X_train)\n",
    "print(\"****** report on test data********************************\")\n",
    "print(accuracy_score(y_pred_1,y_test))\n",
    "print(confusion_matrix(y_pred_1,y_test))\n",
    "print(classification_report(y_pred_1,y_test))\n",
    "print(\"****** report on train  data********************************\")\n",
    "print(accuracy_score(y_pred_2,y_train))\n",
    "print(confusion_matrix(y_pred_2,y_train))\n",
    "print(classification_report(y_pred_2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/anirudh2312/interpretation-and-tuning-of-hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************************************************8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************************************************************88\n",
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Kernel SVM (Training set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#**********************************************************************************88888888\n",
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Kernel SVM (Test set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\Scripts\\\\000000PRACTICE'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
